library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
#Download sample data
#install.packages('remotes')
remotes::install_github("lter/lterdatasampler")
bison = lterdatasampler::knz_bison
head(bison)
summary(duplicated(bison$animal_code))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
#Download sample data
#install.packages('remotes')
remotes::install_github("lter/lterdatasampler")
bison = lterdatasampler::knz_bison
head(bison)
summary(duplicated(bison$animal_code))
#Calculate the age of each bison
bison %<>%
mutate(animal_age = rec_year - animal_yob) %<>%
mutate(animal_sex = as.factor(bison$animal_sex))
head(bison)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter()
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_cowplot(12)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_cowplot(10)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_cowplot(12)
ggplot(data = bison, aes(x = animal_age, y = animal_weight, color = animal_sex)) +
geom_jitter() +
theme_minimal_grid(12)
install.packages('extrafont')
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
library(extrafont)
#Download sample data
#install.packages('remotes')
remotes::install_github("lter/lterdatasampler")
font_import()
fonts()
fonttable()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
library(extrafont)
data <- read.csv(file = "C:\Users\marie\Desktop\Art\timeline")
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.csv")
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.xlsx")
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.xlsx", header = 1)
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.xlsx", header = T)
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.csv", header = T)
data.head()
data.describe()```
#Load data
data <- read.csv(file = "C:/Users/marie/Desktop/Art/timeline.csv", header = T)
data.describe()
describe(data)
data[:5]
data
install.packages('streamgraph')
devtools::install_github("hrbrmstr/streamgraph")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(janitor)
library(magrittr)
library(cowplot)
library(extrafont)
library(streamgraph)
library(extrafont)
library(extrafont)
data
plot.stream <- function(
x, y,
order.method = "as.is", frac.rand=0.1, spar=0.2,
center=TRUE,
ylab="", xlab="",
border = NULL, lwd=1,
col=rainbow(length(y[1,])),
ylim=NULL,
...
){
if(sum(y < 0) > 0) error("y cannot contain negative numbers")
if(is.null(border)) border <- par("fg")
border <- as.vector(matrix(border, nrow=ncol(y), ncol=1))
col <- as.vector(matrix(col, nrow=ncol(y), ncol=1))
lwd <- as.vector(matrix(lwd, nrow=ncol(y), ncol=1))
if(order.method == "max") {
ord <- order(apply(y, 2, which.max))
y <- y[, ord]
col <- col[ord]
border <- border[ord]
}
if(order.method == "first") {
ord <- order(apply(y, 2, function(x) min(which(x>0))))
y <- y[, ord]
col <- col[ord]
border <- border[ord]
}
bottom.old <- x*0
top.old <- x*0
polys <- vector(mode="list", ncol(y))
for(i in seq(polys)){
if(i %% 2 == 1){ #if odd
top.new <- top.old + y[,i]
polys[[i]] <- list(x=c(x, rev(x)), y=c(top.old, rev(top.new)))
top.old <- top.new
}
if(i %% 2 == 0){ #if even
bottom.new <- bottom.old - y[,i]
polys[[i]] <- list(x=c(x, rev(x)), y=c(bottom.old, rev(bottom.new)))
bottom.old <- bottom.new
}
}
ylim.tmp <- range(sapply(polys, function(x) range(x$y, na.rm=TRUE)), na.rm=TRUE)
outer.lims <- sapply(polys, function(r) rev(r$y[(length(r$y)/2+1):length(r$y)]))
mid <- apply(outer.lims, 1, function(r) mean(c(max(r, na.rm=TRUE), min(r, na.rm=TRUE)), na.rm=TRUE))
#center and wiggle
if(center) {
g0 <- -mid + runif(length(x), min=frac.rand*ylim.tmp[1], max=frac.rand*ylim.tmp[2])
} else {
g0 <- runif(length(x), min=frac.rand*ylim.tmp[1], max=frac.rand*ylim.tmp[2])
}
fit <- smooth.spline(g0 ~ x, spar=spar)
for(i in seq(polys)){
polys[[i]]$y <- polys[[i]]$y + c(fit$y, rev(fit$y))
}
if(is.null(ylim)) ylim <- range(sapply(polys, function(x) range(x$y, na.rm=TRUE)), na.rm=TRUE)
plot(x,y[,1], ylab=ylab, xlab=xlab, ylim=ylim, t="n", ...)
for(i in seq(polys)){
polygon(polys[[i]], border=border[i], col=col[i], lwd=lwd[i])
}
}
install.packages("remotes")
remotes::install_github("davidsjoberg/ggstream")
install.packages("remotes")
remotes::install_github("davidsjoberg/ggstream")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(ggstream)
remotes::install_github("davidsjoberg/ggstream")
knitr::opts_chunk$set(echo = TRUE)
beerprod = scan("./data/beerprod.dat")
beerprod =ts(beerprod, freq = 4)
decompdeer = decompose(beerprod, type = 'additive')
decompdeer = decompose(beerprod, type = 'additive')
plot(decompbeer)
decompbeer = decompose(beerprod, type = 'additive')
plot(decompbeer)
decompbeermult = decomp(beerprod, type = 'multiplicative')
decompbeermult = decompose(beerprod, type = 'multiplicative')
plor(decompbeermult)
decompbeermult = decompose(beerprod, type = 'multiplicative')
plot(decompbeermult)
beerprod = scan("beerprod.dat")
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern)
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern, 'r')
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern, 'red')
trendpattern = filter (beerprod, filter = c(1/8, 1/4, 1/4, 1/4, 1/8), sides=2)
plot (beerprod, type= "b", main = "moving average annual trend")
lines (trendpattern)
knitr::opts_chunk$set(echo = TRUE)
beerprod = scan("./data/beerprod.dat")
beerprod =ts(beerprod, freq = 4)
#detrend
x = diff(beerprod)
#FFT function - n in the sqrt
I = abs(fft(x)/sqrt(72))^2
#Pick out the first half of the frequencies - scale slightly
P = (4/36)*I[1:36]
#Crete harmonic frequencies
freq = (0:36)/72
plot(freq,P,type="l")
#detrend
x = diff(beerprod)
#FFT function - n in the sqrt
I = abs(fft(x)/sqrt(72))^2
#Pick out the first half of the frequencies - scale slightly
P = (4/36)*I[1:37]
#Crete harmonic frequencies
freq = (0:36)/72
plot(freq, P, type="l")
knitr::opts_chunk$set(echo = TRUE)
###Install packages
#install.packages("astsa") # nolint
library(astsa)
x=ts(scan("./data/econpredictor.dat"))
x=ts(scan("./data/econpredictor_1.dat"))
y=ts(scan("./data/econmeasure_0.dat"))
plot.ts(x,y,xy.lines=F,xy.labels=F)
regmodel=lm(y~x)
summary(regmodel)
acf2(residuals(regmodel))
ar1res = sarima (residuals(regmodel), 1,0,0, no.constant=T) #AR(1)
xl = ts.intersect(x, lag(x,-1)) # Create matrix with x and lag 1 x as elements
xnew=xl[,1] - 0.6488*xl[,2] # Create x variable for adjustment regression
yl = ts.intersect(y,lag(y,-1)) # Create matrix with y and lag 1 y as elements
ynew=yl[,1]-0.6488*yl[,2] # Create y variable for adjustment regression
adjustreg = lm(ynew~xnew) # Adjustment regression
summary(adjustreg)
acf2(residuals(adjustreg))
install.packages("orcutt")
library(orcutt)
cochrane.orcutt(regmodel)
summary(cochrane.orcutt(regmodel))
library(astsa)
soi= scan("soi.dat")
soi= scan("./data/soi.dat")
rec = scan("./data/recruit.dat")
soi=ts (soi)
rec = ts(rec)
ccfvalues =ccf (soi, rec)
ccfvalues
lag2.plot (soi, rec, 10)
alldata=ts.intersect(rec,reclag1=lag(rec,-1), reclag2=lag(rec,-2), soilag5 = lag(soi,-5),
soilag6=lag(soi,-6), soilag7=lag(soi,-7), soilag8=lag(soi,-8), soilag9=lag(soi,-9),
soilag10=lag(soi,-10))
tryit = lm(rec~soilag5+soilag6+soilag7+soilag8+soilag9+soilag10, data = alldata)
summary (tryit)
acf2(residuals(tryit))
tryit2 = lm(rec~reclag1+reclag2+soilag5+soilag6+soilag7+soilag8+soilag9+soilag10,
data = alldata)
summary (tryit2)
acf2(residuals(tryit2))
tryit3 = lm(rec~reclag1+reclag2+ soilag5+soilag6, data = alldata)
summary (tryit3)
acf2(residuals(tryit3))
knitr::opts_chunk$set(echo = TRUE)
#install.packages("astsa")
library(astsa)
library(dplyr)
library(tidyverse)
### Import Snow Data
s2data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS2.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
s2data = na.omit(s2data)
s6data = read.csv("D:/1_DesktopBackup/Feng Research/0_MEF Snow Hydology/mef-snowhydro/Data and Codes/Cleaned Data/01_cleanedsnowdataS6.csv",
header = TRUE,
sep = ",",
#col.names = c("time", "northing", "easting", "zones", "stakes",
#              "aspect", "slope", "watershed")
)
s6data = na.omit(s6data)
View(s2data)
#Check data
head(s2data)
#Groupby date and zone -- eliminate stake names
s2data_grouped  = s2data %>%
group_by(time, zones) %>%
summarize(mean_depth = mean(depths))
head(s2data_grouped)
s6data_grouped  = s6data %>%
group_by(time, zones) %>%
summarize(mean_depth = mean(depths))
head(s6data_grouped)
#Set time series
s2_depths = ts(s2data_grouped$mean_depth)
s2_times = ts(s2data_grouped$time)
s2_zones = ts(s2data_grouped$zones)
s6_depths = ts(s6data_grouped$mean_depth)
s6_times = ts(s6data_grouped$time)
s6_zones = ts(s6data_grouped$zones)
#Run S2 Repeated Measures ANOVA
Y = s2data$depths
aov.p = aov(Y ~ (factor(zones)*factor(time))+Error(factor(stakes)), s2data)
summary(aov.p)
#Results -- Betweens are not significant, as we expected. There is no sig difference between the zones. Within a zone, however, there is a significant trend with time (as we would hope) and there is a significant interaction with zone and time, so even though the overall means might be different there is a slight difference in slopes.
#Run S2 Repeated Measures ANOVA
Y = s6data$depths
aov.p = aov(Y ~ (factor(zones)*factor(time))+Error(factor(stakes)), s6data)
summary(aov.p)
#Results - Between the zones there is a significant difference (yay!) and within the zones there is a signifcant relationship with time, expected, and a slight difference in slopes, although not as significant as the S2 data.
knitr::opts_chunk$set(echo = TRUE)
#Imports
#Basic R packages
#install.packages(tidyverse)
#install.packages(dplyr)
#install.packages(ggplot2)
library(tidyverse)
library(dplyr)
library(ggplot2)
#Specifically for LAI
install.packages(“hemispheR”)
#Imports
#Basic R packages
#install.packages(tidyverse)
#install.packages(dplyr)
#install.packages(ggplot2)
library(tidyverse)
library(dplyr)
library(ggplot2)
#Specifically for LAI
install.packages('hemispheR')
library(hemispheR)
install.packages("hemispheR")
knitr::opts_chunk$set(echo = TRUE)
#Imports
#Basic R packages
#install.packages(tidyverse)
#install.packages(dplyr)
#install.packages(ggplot2)
library(tidyverse)
library(dplyr)
library(ggplot2)
#Specifically for LAI
#install.packages('hemispheR')
library(hemispheR)
setwd("C:/Users/marie/Desktop/hemispheR")
image<-system.file('samples/sample (1).JPG', package='hemispheR')
image
img<-import_fisheye(image,
channel = 3,
circ.mask=list(xc=1136,yc=852,rc=754),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
image<-system.file('samples/sample1.JPG', package='hemispheR')
image <- system.file('samples/sample1.JPG', package='hemispheR')
img <- import_fisheye(image,
channel = 3,
circ.mask=list(xc=1136,yc=852,rc=754),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
image <- system.file('samples/sample1.jpg', package = 'hemispheR')
img <- import_fisheye(image,
channel = 3,
circ.mask=list(xc=1136,yc=852,rc=754),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
img <- import_fisheye(image,
channel = 3,
circ.mask=list(xc=1136,yc=852,rc=754),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
image
image
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
circ.mask=list(xc=1136,yc=852,rc=754),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
#circ.mask=list(xc=1136,yc=852,rc=754),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
circ.mask=list(xc=3000,yc=2000,rc=900),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
circ.mask=list(xc=3000,yc=2000,rc=1300),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
#circ.mask=list(xc=3000,yc=2000,rc=1300),
circ.mask = camera_fisheye("D300+Sigma-4.5"),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
circ.mask=list(xc=3000,yc=2000,rc=1600),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
circ.mask=list(xc=3000,yc=2000,rc=1400),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
#Import Photo
img <- import_fisheye('samples/sample1.jpg',
channel = 3,
circ.mask=list(xc=3000,yc=2000,rc=1450),
circular=TRUE,
gamma=2.2,
stretch=FALSE,
display=TRUE,
message=TRUE)
img.bw <- binarize_fisheye(img,
method='Otsu',
zonal=FALSE,
manual=NULL,
display=TRUE,
export=FALSE)
gap.frac<-gapfrac_fisheye(
img.bw,
maxVZA = 90,
lens = "FC-E8",
startVZA = 0,
endVZA = 70,
nrings = 7,
nseg = 8,
display=TRUE,
message = FALSE
)
gap.frac<-gapfrac_fisheye(
img.bw,
maxVZA = 90,
lens = "Sigma 4.5",
startVZA = 0,
endVZA = 70,
nrings = 7,
nseg = 8,
display=TRUE,
message = FALSE
)
gap.frac<-gapfrac_fisheye(
img.bw,
maxVZA = 90,
lens = "Sigma-4.5",
startVZA = 0,
endVZA = 70,
nrings = 7,
nseg = 8,
display=TRUE,
message = FALSE
)
canopy<-canopy_fisheye(gap.fracv)
canopy<-canopy_fisheye(gap.frac)
canopy
unlink("LAI_photo_processing_cache", recursive = TRUE)
photos <- list.files(path = 'samples')
photos
photos[1]
paste("samples/",photos[i])
paste("samples/",photos[1])
paste("samples/",photos[1], sep = '')
#Calculate LAI
canopy <- canopy_fisheye(gap.frac)
print(canopy)
data.frame(canopy)
data.frame(canopy)
canopyLAI <- data.frame()
canopyLAI
canopydf <- data.frame(canopy)
rbind(canopyLAI, canopydf)
#Tell R where to find the function to batch run LAI
source("lai-batch.R")
#Run batch function on all sample photos
batchLAI('samples')
